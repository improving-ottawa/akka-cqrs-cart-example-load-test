
-------------------------------------------------------------------------------------
-- STEP-0: General information & Preparations
-------------------------------------------------------------------------------------

DSE Configuration:
~~~~~~~~~~~~~~~~~~~~
General configuration: https://docs.datastax.com/en/dse/6.8/dse-dev/datastax_enterprise/config/configTOC.html

For recommended production settings: https://docs.datastax.com/en/dse/6.8/dse-dev/datastax_enterprise/config/configRecommendedSettings.html

Recommended capacity planning guide for DSE: https://docs.datastax.com/en/dseplanning/docs/capacityPlanning.html


Clearing the data from DataStax Enterprise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
https://docs.datastax.com/en/dse/6.8/dse-dev/datastax_enterprise/operations/opsClearData.html

Please refer to Package installation steps. Please also see the "Stop" details before clearing data.


Configuration files in the DSE node:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Configuration files are available at '/etc/dse/cassandra/' in a DSE node.


Log files in the DSE node:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Log files are available at '/var/log/cassandra/' in a DSE node.


Starting and stopping DSE cluster node from command-line:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
sudo service dse start
sudo service dse stop


DataStax enterprise license terms:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
https://www.datastax.com/legal/datastax-enterprise-terms


See list of available Ubuntu images in GCP:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gcloud compute images list --filter ubuntu-os-cloud

... ... ...
... ... ...
NAME: ubuntu-1804-bionic-v20230308
PROJECT: ubuntu-os-cloud
FAMILY: ubuntu-1804-lts
DEPRECATED:
STATUS: READY
... ... ...
... ... ...
NAME: ubuntu-2004-focal-v20230302
PROJECT: ubuntu-os-cloud
FAMILY: ubuntu-2004-lts
DEPRECATED:
STATUS: READY
... ... ...
... ... ...


-------------------------------------------------------------------------------------
-- STEP-1: Deploy DSE OpsCenter in GCP
-------------------------------------------------------------------------------------


Launch the Ubuntu 18.04 LST based VM in GCP:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gcloud compute instances create opscenter --image ubuntu-1804-bionic-v20230308 --image-project ubuntu-os-cloud --local-ssd interface=nvme --machine-type=n2-highmem-2 --zone=northamerica-northeast2-a


From SSH terminal issue the following commands:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
$> sudo apt-get update
$> sudo apt update


Install OpenJDK 8 install on Ubuntu:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
REF: https://docs.datastax.com/en/jdk-install/doc/jdk-install/installOpenJdkDeb.html

$> sudo apt-get install openjdk-8-jdk



Install DSE OpsCenter on GCP VM:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
REF: https://docs.datastax.com/en/installing/docs/opscInstallDeb.html

Once installed, configure firewall to enable http & https traffic and ingress on port 8888

And then launch the OpsCenter UI @ http://opscenter-host:8888/  where 'opscenter-host' is the public IP address of VM instance where you installed the DSE OpsCenter.




-- -------------------------------------------------------------------------------
-- STEP-2: Instanciate & prepare 3 VMs in GCP for the DataStax Enterprise cluster
-- --------------------------------------------------------------------------------

Issue the following commands via CLOUD SHELL Terminal in GCP Console.

gcloud compute instances create dse-1 --image ubuntu-2004-focal-v20230302 --image-project ubuntu-os-cloud --local-ssd interface=nvme --local-ssd interface=nvme --local-ssd interface=nvme --local-ssd interface=nvme --machine-type=n2-highmem-4 --zone=northamerica-northeast2-a

gcloud compute instances create dse-2 --image ubuntu-2004-focal-v20230302 --image-project ubuntu-os-cloud --local-ssd interface=nvme --local-ssd interface=nvme --local-ssd interface=nvme --local-ssd interface=nvme --machine-type=n2-highmem-4 --zone=northamerica-northeast2-a

gcloud compute instances create dse-3 --image ubuntu-2004-focal-v20230302 --image-project ubuntu-os-cloud --local-ssd interface=nvme --local-ssd interface=nvme --local-ssd interface=nvme --local-ssd interface=nvme --machine-type=n2-highmem-4 --zone=northamerica-northeast2-a


Configure the VMs for SSH connection:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# If not already done, Generate SSH keys on your local machine:
ssh-keygen -t rsa -f ~/.ssh/gcloud-ssh-dse-vms -C syed.junaid@yoppworks.com
ssh-keygen -p -N "" -m pem -f ~/.ssh/gcloud-ssh-dse-vms

# Transfer Public Key to the VM instance(s) once they are created:
# Print public key
$> cat ~/.ssh/gcloud-ssh-dse-vms.pub

# <Edit> your VM instance in Google Cloud console and select <ADD ITEM> under 'SSH Keys', and copy your Public Key (from previous step) there.


Create 'VPC Firewall rules' for DSE cluster:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Description:  dse
Network: default
Direction: ingress

Targets: Specified target tags

Target tags: dse-ports

Source filter: IPv4 ranges

# NOTE: beside the first '0.0.0.0/0' the following one to two range values will depend
#       on Public IP addresses of your cluster nodes.
#       (Please enhance this description if you know better)
Source IPv4 ranges: 0.0.0.0/0, 34.124.0.0/24, 34.130.0.0/24

# NOTE: The better choice may be 'Specified protocols and ports' with TCP protocol
#       and
#           9042,9142,7000,7001,7199,10000,9180,9100,9160,19042,19142
#       ports,
#       for the following option.
#       However, I was facing a connectivity issue, and selecting 'Allow all' resolved it for me.
Protocols and Ports: 'Allow all'


Configure firewall rules for DSE cluster nodes:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Edit dse-1, dse-2, and dse-3 nodes (created above) in GCP console,
# and, for each:
Allow HTTP and HTTPS traffic in 'firewalls' section AND add 'dse-ports' tag


Connect to each of the GCP VM instances via SSH from local machine terminal:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# SSH into each of the above 3 VMs to ensure each one has 4 NVMe SSD of 375GB each mounted
# ssh -i ~/.ssh/gcloud-ssh-dse-vms your-gcloud-user-id@vm-public-ip
# For example:
$> ssh -i ~/.ssh/gcloud-ssh-dse-vms syed.junaid@34.130.37.68


List attached NVMe disk drives :
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
$> lsblk

Should have similar to the following as part of the Output
... ... ...
... ... ...
nvme0n1 259:0    0   375G  0 disk
nvme0n2 259:1    0   375G  0 disk
nvme0n3 259:2    0   375G  0 disk
nvme0n4 259:3    0   375G  0 disk
... ... ...
... ... ...


Install Open JDK 8 on each of the 3 dse-x nodes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
REF: https://docs.datastax.com/en/jdk-install/doc/jdk-install/installOpenJdkDeb.html

sudo apt-get update
sudo apt-get install openjdk-8-jdk
java -version

Create RAID0 from attached NVMe disks:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
https://cloud.google.com/compute/docs/disks/add-local-ssd#formatandmount
Please see 'Format and mount multiple local SSD partitions into a single logical volume' section

sudo apt update && sudo apt install mdadm --no-install-recommends

find /dev/ | grep google-local-nvme-ssd

sudo mdadm --create /dev/md0 --level=0 --raid-devices=4 \
 /dev/disk/by-id/google-local-nvme-ssd-0 \
 /dev/disk/by-id/google-local-nvme-ssd-1 \
 /dev/disk/by-id/google-local-nvme-ssd-2 \
 /dev/disk/by-id/google-local-nvme-ssd-3

sudo mdadm --detail --prefer=by-id /dev/md0

sudo mkfs.ext4 -F /dev/md0

sudo mkdir -p /mnt/disks/cassandra_data

sudo mount /dev/md0 /mnt/disks/cassandra_data

sudo chmod a+w /mnt/disks/cassandra_data

echo UUID=`sudo blkid -s UUID -o value /dev/md0` /mnt/disks/cassandra_data ext4 discard,defaults,nofail 0 2 | sudo tee -a /etc/fstab

cat /etc/fstab

Create 'cassandra' User:
~~~~~~~~~~~~~~~~~~~~~~~~~
sudo adduser cassandra

NOTE: provide 'cassandra' as password and leave the following at the default empty (just enter on each)
        Full Name []:
        Room Number []:
        Work Phone []:
        Home Phone []:
        Other []:

sudo usermod -aG sudo cassandra


Create the required folders in RAID0:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
sudo chown -R cassandra:cassandra /mnt/disks/cassandra_data
sudo chmod 770 /mnt/disks/cassandra_data

sudo mkdir /mnt/disks/cassandra_data/data
sudo chown -R cassandra:cassandra /mnt/disks/cassandra_data/data
sudo chmod 755 /mnt/disks/cassandra_data/data

sudo mkdir /mnt/disks/cassandra_data/metadata
sudo chown -R cassandra:cassandra /mnt/disks/cassandra_data/metadata
sudo chmod 755 /mnt/disks/cassandra_data/metadata

sudo mkdir /mnt/disks/cassandra_data/saved_caches
sudo chown -R cassandra:cassandra /mnt/disks/cassandra_data/saved_caches
sudo chmod 755 /mnt/disks/cassandra_data/saved_caches

sudo mkdir /mnt/disks/cassandra_data/cdc_raw
sudo chown -R cassandra:cassandra /mnt/disks/cassandra_data/cdc_raw
sudo chmod 755 /mnt/disks/cassandra_data/cdc_raw

sudo mkdir /mnt/disks/cassandra_data/commitlog
sudo chown -R cassandra:cassandra /mnt/disks/cassandra_data/commitlog
sudo chmod 755 /mnt/disks/cassandra_data/commitlog

sudo mkdir /mnt/disks/cassandra_data/hints
sudo chown -R cassandra:cassandra /mnt/disks/cassandra_data/hints
sudo chmod 755 /mnt/disks/cassandra_data/hints

sudo ls -al /mnt/disks/cassandra_data/



-- --------------------------------------------------------------------------------
-- STEP-3: Installing a DataStax Enterprise cluster using Lifecycle Manager
-- --------------------------------------------------------------------------------

In 'SSH credentials' section (one time):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
a.) Select 'Private Key' as 'SSH Login' option
b.) Copy 'gcloud-ssh-dse-vms' private key contents in 'SSH Private Key' box
c.) enter 'syed.junaid' in the Login User box
d.) Select 'SUDO' as 'Escalation Privileges' choice and leave the 'SUDO to this user' & 'SUDO password' boxes empty


Configure 'Config Profiles' section (one time):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Go to 'Config Profiles' section and assign values for the following properties, as shown below:

Name: test
DataStax Enterprise Version: 6.8.33


Go into 'Cassandra.yaml' section and assign values for following properties as shown below:

    authenticator:  AllowAllAuthenticator
    authorizer:     AllowAllAuthorizer
    role_manager:   DseRoleManager

    server_encryption_options:
        internode_encryption:   none

    General:
    partitioner:    Murmer3Partitioner

    data_file_directories:      /mnt/disks/cassandra_data/data
    metadata_directory:         /mnt/disks/cassandra_data/metadata
    saved_caches_directory:     /mnt/disks/cassandra_data/saved_caches
    cdc_raw_directory:          /mnt/disks/cassandra_data/cdc_raw
    commitlog_directory:        /mnt/disks/cassandra_data/commitlog
    hints_directory:            /mnt/disks/cassandra_data/hints

    Cluster Communication:
    endpoint_snitch:    GossipingPropertyFileSnitch



Configure 'Repositories' (one time):
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Go into 'Repositories' in Lifecycle Manager and assign values for following properties as shown below:

Name:  test
Repository:   select 'Acess DataStax repo'
Use Configured HTTP proxy:  leave it CHECKED (i.e. leave it as-is)



Deploy the cluster:
~~~~~~~~~~~~~~~~~~~~
Follow the instructions @
https://docs.datastax.com/en/opscenter/docs/6.8/LCM/opscLCMInstallDSE.html
for this deployment.


In Lifecycle Manager: Clusters definition:

For Clusters:

Name:   dse
SSH Credentials:   Syed Junaid (it will be the user name according to your 'SSH Credentials' settings, see above)

Repository:  test
config Profile: test


For Datacenters:

Name:   improving
Config Profile: test
SSH Credentials:   Syed Junaid (it will be the user name according to your 'SSH Credentials' settings, see above)

Workloads: Cassandra


For Nodes:

Name:   dse-1
        (or dse-2 or dse-3 or something else according the name you assigned to the VM when you created it using gCloud command)

Rack:   a (or b or c)

SSH IP Address:  Private IP address of the VM (see Google Cloud Console for this IP address)

SSH Credentials:   Syed Junaid (it will be the user name according to your 'SSH Credentials' settings, see above)

Config Profile:  test

Seed Node:   Select 'Make this a seed node' option for the first node in the cluster. Select 'Automatically choose' for other nodes.


To initiate the actual installation:

SELECT 'Install' from  '...' menu (next to dse-1 in Nodes list 'Lifecycle Manager:Cluster' deployment UI).
  THEN select 'True' for 'Auto bootstrap', and 'Lifecycle Manager Default' for others.



Check directories after deployment:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cat /etc/dse/cassandra/cassandra.yaml |grep director

To find out deployed Linux OS and Version for DSE nodes
$> cat /etc/os-release
